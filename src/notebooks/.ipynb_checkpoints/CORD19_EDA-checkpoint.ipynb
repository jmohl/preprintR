{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration of CORD_19 covid literature dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "One of the most amazing things about the response to the COVID-19 pandemic has been the truly incredible amount of research released on extremely short timelines. While this is an incredible human accomplishment, the generation of this much science exacerbates an existing problem facing many scientific researchers: it is often impossible to read every piece of potentially relevant research while still maintaining a productive output in the lab.\n",
    "\n",
    "This problem is made even worse by the existence of low quality science (whether intentionally fraudulent or simply careless) which must be waded through in order to find useful work. Ideally, it is the role of peer reviewed journals to solve this problem (though this process is [not perfect](https://statmodeling.stat.columbia.edu/2020/06/15/surgisphere-scandal-legacy-media-lancet-still-dont-get-it/) and journals are not without other flaws). However, simply publishing something in a professional journal is no guarantee that it is not ‘garbage science’. In fact, this whole project of evaluating the COVID-19 literature was inspired for me by [this graphic](https://www.economist.com/graphic-detail/2020/05/30/how-to-spot-dodgy-academic-journals) from the economist, which shows that ~40% of the journals launched in 2018 were essentially little more than pay to publish scams! And this number has been growing since 2010! Clearly there is a market for writing and publishing junk science, and I see no reason why coronavirus related research would be exempt from this trend.\n",
    "\n",
    "Most researchers are aware of the reputable journals in their own fields, and so are unlikely to waste time reading work printed in this type of predatory journal. However there has been a trend in the scientific community generally (and the pandemic community particularly) towards getting the latest science from preprint servers like MedRxiv or BioRxiv. These manuscripts have not yet been through peer review, and so there is no filter in place separating quality research from junk.\n",
    "\n",
    "This is a potential disaster. It's not always trivial to spot bad science, and countless hours could be wasted on this process that could be spent in much more productive ways. Not to mention the cases where such work is [both fraudulent and actively harmful](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)31180-6/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "There is apparently a thriving market for publishing shoddy science, and the peer review process for filtering out this poor quality work is relatively slow. Thus pre-print servers like MedRxiv and BioRxiv are potentially riddled with fraudulent or erroneous papers, wasting critical researcher time. I would like to **develop a tool for automatically flagging these low quality papers**, but first I need to spend some time looking at the raw data to understand what types of features might be usable for solving this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [CORD-19](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge) dataset is a webscraped dataset of nearly 200,000 articles dealing with COVID-19, SARS-COV-2 and related coronaviruses. This is provided as an open source tool through Kaggle, and is a great resource for understanding the evolving literature on this topic.\n",
    "\n",
    "**Other datasets**\n",
    "\n",
    "[PMC open access subset](https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/) is a collection of nearly 2 million scientific articles. These span a much wider range of topics and should be useful for getting a broader understanding of the literature (particularly important for spotting what might be considered bad science)\n",
    "\n",
    "word vector encodings trained on biomedical research: [1](https://github.com/RaRe-Technologies/gensim-data) [2](http://bioasq.org/news/bioasq-releases-continuous-space-word-vectors-obtained-applying-word2vec-pubmed-abstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
