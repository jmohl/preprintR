---
title: "CORD19-EDA"
author: "Jeff"
date: "7/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

## Exploring CORD-19 dataset for ML tools
The [CORD-19 dataset](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/) is a collection of machine-readable literature related to COVID-19. This data is made available to facilitate text mining of the evolving COVID-19 literature, and offers a valuable resource for me because it includes a (nicely) annotated corpus of research topics as well as a pretrained word embedding that I can use. This last part is especially convenient because biomedical literature does is not particularly well served by natural language embeddings trained on other corpora.

First thing I want to do is take a look at the data

## Load data
Note that this is a pretty big metadata file and it takes a while to load.

```{r load-data}
metadata <- read.csv(file = '../data/CORD19/metadata.csv')
head(metadata)
```

Think I would like to make this into a nicer dataframe [here is a useful example](https://www.kaggle.com/danielwolffram/cord-19-create-dataframe) note this is done in pandas)
Right away this metadata file is going to be extremely useful. It contains not only the objvious things (title, author, journal, date) but also the entire abstract for each as well as an indicator field for whether it is COVID related or not. This is great because I can immediately use this to look at one of the first things I wanted to see: how much literature is coming out related to COVID?

```{r literature-over-time}

```

