## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(statsr)
library(BAS)
library(broom)
library(GGally)
library(MASS)
library(dplyr)

```

### Load data

```{r load-data}
load("movies.Rdata")
```

***
### Introduction

We have been tasked with using publicly available audience data from Rotten Tomatoes and IMDB to determine what attributes make a movie popular with audiences. Specifically our boss wants use to use Bayesian regression techniques to learn the relationship between various movie features and the variable of interest (audience_score). She is also interested in learning something new about movies, whatever that may be.

* * *

## Part 1: Data

This data set consists of randomly sampled movies which were released before 2016. The information for all of these movies was pulled from two websites, IMDB and Rotten Tomatoes. Both of these websites contain factual information about the movie (i.e. cast, release date, genre) as well as subjective evaluations of the movie in the form of audience and critic reviews.

The movies here are sampled randomly, which means that any information we are able to extract should generalize to other similar movies (released in the United States, between 1970 and 2016). It is possible that overall audience tastes have changed since 2016, but it is unlikely that they have rapidly and dramatically shifted in less than 3 years, so it would likely be fair to generalize our findings into the present and near future as well.

It is important to note that the reviews which are the source of our variable of interest (audience score) are given voluntarily by people who log in to either of the websites. This is not a random sample of the population, because reviewers are self selected. It is possible that this self selection will bias reviews towards people who feel more strongly negatively or positively about the film, and it cannot be considered a representative sample of the US population at large. However, self selected reviewers should correlate at least somewhat with the general population, and so we can still get useful information from this data for our purposes.

Finally this is an observational study and not an experiment. "Subjects" are people who both voluntarily went and saw a movie that they thought would be interesting and then took time out of their day to leave a review on one of the two source websites. This is very different from a controlled experiment with randomized assignment. Therefore we cannot make any causal claims about any particular feature affecting our variable of interest directly.

* * *

## Part 2: Data manipulation

We need to build a few new fields to go in to our model: feature_film, drama, mpaa_rating_R, oscar_season, and summer_season. We will do this using the mutate command.

```{r add-new-fields}

movies <- movies %>% 
  mutate(feature_film = factor(ifelse(title_type == 'Feature Film','yes','no')),
         drama = factor(ifelse(genre == 'Drama','yes','no')),
         mpaa_rating_R = factor(ifelse(mpaa_rating == 'R','yes','no')),
         oscar_season = factor(ifelse(thtr_rel_month %in% c(10,11,12),'yes','no')),
         summer_season = factor(ifelse(thtr_rel_month %in% c(5,6,7,8),'yes','no')))

# double checking to make sure these new variables look correct and have the desired yes/no format
movies %>% 
  dplyr::select(feature_film,drama,mpaa_rating_R,oscar_season,summer_season) %>%
  summary()

```


* * *

## Part 3: Exploratory data analysis

**Research Question: What movie features are predictive of a given movie's popularity, as measured by the 'Audience Score'**

Before we do anything, I want to look at the data and make sure there aren't a ton of NA's.

```{r data_clean}
incomplete_movies = movies[!complete.cases(movies),]

colnames(incomplete_movies[,colSums(is.na(incomplete_movies))>0])

movies = movies[!is.na(movies$runtime),]

```
Looking through the columns which have at least one 'NA' term, the only one we potentially care about is the 1 which has a run_time of NA. All of the other variables are not something we will include in our eventual model, so we don't need to worry about them. Here I have just removed the one offending row, but an alternative would have been to replace it with some mean/median value. Since it is just one data point, I am not going to worry about it.

Now that we have cleaned our data, the first thing we want to do is look at our 'audience_score' variable since that is our variable of interest for this project.

```{r audience_score_EDA}


ggplot(data=movies,aes(x=audience_score)) +
  geom_histogram(binwidth = 2)

summary(movies$audience_score)

sprintf('standard deviation: %2.2f',sd(movies$audience_score))

```
From these initial plots and summary statistics we can see there there is a very broad range of audience opinion in our sample set, with a mean of 62.36 points out of a possible 100, and a standard deviation of 20.22. From the histogram we can also see that the audience opinions are not very normally distributed. There appears to be some bimodality to the distribution as well as a large left tail.

Next we want to get an idea of the relationship between our variable of interest 'audience_score' and some of the more likely independent variables. For this paper I've chosen all of the new variables defined above, as well as best_pic_nominee and top200_box variables (which we should naively expect to be very strong predictors of movie popularity, because they are themselves reflective of a movie's success)

```{r EDA-plots}

ggplot(data=movies,aes(x=drama,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=feature_film,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=mpaa_rating_R,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=oscar_season,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=summer_season,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=best_pic_nom,y=audience_score)) +
  geom_boxplot()

ggplot(data=movies,aes(x=top200_box,y=audience_score)) +
  geom_boxplot()

```
Looking at all of these plots it seems like there is a fairly strong positive relationship with audience score for the new drama variable, and a strong negative relationship with the feature feature film factor (with the alternatives being Documentary and TV movie, but mostly Documentary). All of the other factors plotted here have weak relationships with audience_score, but that doesn't mean they are completely irrelevant. We will determine this later on in the model fitting step. 

The above relationships that we see in the EDA plots are not very surprising, and generally agree with my assumptions. For instance I would expect that movies released during "oscar season" would generally be higher quality than one released during the summer season. So it is not surprising that these variables are predictive in opposite directions.

One thing we might want to do as well is to compare summary statistics for a few of these plots, so that we are not relying on visual inspection alone. 

```{r summary-stats}

print('Summary stats: all movies')
movies %>%
  dplyr::select(audience_score,oscar_season, best_pic_nom) %>%
  summary()

print('Summary stats: dramas')
movies %>%
  filter(drama == 'yes') %>%
  dplyr::select(audience_score, oscar_season, best_pic_nom) %>%
  summary()

print('Summary stats: oscar season')
movies %>%
  filter(oscar_season == 'yes') %>%
  dplyr::select(audience_score, best_pic_nom) %>%
  summary()
```
Comparing the two subsets of results for the 'dramas' and 'oscar_season' variables we see that indeed these both have higher means and medians than the entire data set, confirming what was seen in the plots. Also it is interesting to note that the "oscar_season" movies dominate the nominations for best picture, as there are 16/22 nominations from this time period despite being only ~1/3rd of the total number of movies.


* * *

## Part 4: Modeling

From out EDA above we know that there are both strong and weak relationships between our dependent variable 'audience_score' and our many independent variables. We will now use a Bayesian regression approach to determine which of the independent variables actually provide us with valuable information for predicting audience_score. We first begin with a full model that includes all of the relevant data features.

```{r complete_model}
m_movies_full <- lm(audience_score ~ feature_film + drama + runtime + mpaa_rating_R + thtr_rel_year + oscar_season + summer_season + imdb_rating+ imdb_num_votes + critics_score + best_pic_nom + best_pic_win + best_actor_win + best_actress_win + best_dir_win + top200_box, data = movies)

tidy(m_movies_full)

```

Just glancing at the results of fitting this full model it is clear that there are a lot of parameters we will end up dropping. So let's just go ahead and perform model selection to find the best model (using BIC as our criterion).

```{r stepwise_model_selection}
n=nrow(movies)
m_movies_selected = stepAIC(m_movies_full,k=log(n),trace=0)
tidy(m_movies_selected)
```
Before we move on to interpretation, lets make sure that our model is valid by running some diagnostics.

```{r residuals-plots}

ggplot(data = m_movies_selected, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted values", y = "Residuals")

ggplot(data = m_movies_selected, aes(x = .resid)) +
  geom_histogram(binwidth = 2) +
  xlab("Residuals")

m_movies_selected_aug = augment(m_movies_selected)
ggplot(m_movies_selected_aug) +
  geom_qq(aes(sample = .std.resid)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(x = "Theoretical quantiles", y = "Standardized residuals")
```

The residuals seem to have a slight fan shape, which we might be able to address by (for example) log transforming the score. However, these residuals are approximately normally distributed, which means our model assumptions seem fine and we can move on to interpretation.

This model selection strategy ended up providing us with a much simpler model. Instead of having 15 variables our model uses only the runtime, imdb_score, and critics_score variables (plus intercept).The effect sizes for these features were approximately -.05, 15, .07. This tells us that longer movies are ranked slightly worse, while movies that are ranked highly on IMDB and by critics perform better. However I don't really like this model, because I don't think there is a lot of benefit of saying that critic's score is informative about audience score, when that should be an assumption we have from the beginning anyways (at least broadly, critics and audiences can agree about the quality of a movie).

This makes a good opportunity to use a model averaging approach, to see if we can get a little bit better model.

```{r bma}
bma_movies <- bas.lm(audience_score ~ feature_film + drama + runtime + mpaa_rating_R + thtr_rel_year + oscar_season + summer_season + imdb_rating + imdb_num_votes + critics_score + best_pic_nom + best_pic_win + best_actor_win + best_actress_win + best_dir_win + top200_box, data = movies,
                   prior = "BIC", 
                   modelprior = uniform())

summary(bma_movies)
```


Now things are a little more interesting. First we note that the best model is still only a little more likely than the second most likely model (which excludes the runtime feature) by comparing their posterior probabilities (.1297 and .1293). We can also see that there are a few features, such as the oscar related fields, which might add a little bit of information to our model. Other than that we see that despite having many features to draw from our model is just not going to do a great job (the best R^2 values are around .75). This is likely because there are a ton of complicated things that go in to making a good movie that are not at all covered by this very limited dataset.


* * *

## Part 5: Prediction

We are going to predict the audience score for a new movie from 2016: 'The Accountant'. The data for this movie are going to be taken from imdb and rotten tomatoes at the following links and entered by hand below:
https://www.imdb.com/title/tt2140479/?ref_=ttls_li_tt
https://www.rottentomatoes.com/m/the_accountant_2016

```{r prediction}
accountant <- data.frame(critics_score = 51, best_pic_nom = "no",drama = "yes",audience_score=76,imdb_rating = 7.5, imdb_num_votes =231402, feature_film = 'yes',runtime = 128,mpaa_rating_R='yes',thtr_rel_year = 2016,oscar_season = 'yes', summer_season = 'no',best_pic_win = 'no',best_actor_win = 'no',best_actress_win = 'no',best_dir_win='no',top200_box = 'no')

acc_pred = predict(bma_movies,accountant,estimator = "BMA",se.fit = 1)
acc_int = confint(acc_pred, estimator = "BMA")

acc_int

```

Our model-averaging model predicts that the score will be 76.3, with a 95% confidence interval between 56.6 and 96.31. The true score is 76, so our model happened to get the score almost exactly right. However our confidence intervals are quite wide, which tells us that we cannot expect to always be this accurate and it was mostly due to luck that we had a real error of 0.2 points for this selection.

* * *

## Part 6: Conclusion

We were able to use publicly available data from IMDB and rotten tomatoes to determine several features that are predictive of audience appreciation as measured by audience_score. The most influential variables were critic score, imdb rating, and runtime.  We were then able to use this model to predict the score for a movie that was not part of the data set, 'The Accountant' from 2016, accurately (actual score was well within the 95% confidence interval).

Overall if I was to be honest about this model I would say that this data set provides very little useful information to our hypothetical film executive employer. Almost none of these features available in this data set are likely to help when it comes to improving audience scores. Instead the features that matter all basically measure the same thing: how much do people like the film.

This research could be improved by looking at features in a much more fine grained analysis. For instance I would expect that certain writer, actors, and directors reliably make films that result in high audience scores, and this type of analysis could be carried out with a larger data set and by doing a much more thorough EDA and feature engineering step.
